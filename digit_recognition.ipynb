{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Build a Digit Recognition Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "In this project, you will use logistic regression, deep neural networks, and convolutional neural networks to create a digit recognition deep learning system. First, you will implement the digit recognition system using a simple logistic regression multiclass classifier.  Afterwards, the model will be upgraded using a deep neural network.  Finally, the digits will be recognized using a CNN and performance will be compared among the various implementations. The dataset used will be the MNIST dataset, and the deep learning framework to implement the algorithms will be TensorFlow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import various functions to be used throghout the project\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "#import tensorflow framework as well as the MNIST dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import os\n",
    "import pylab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reset the Tensorflow graph and begin a new session\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "cell finished\n"
     ]
    }
   ],
   "source": [
    "#read in the MNIST data \n",
    "mnist = input_data.read_data_sets('/tmp/data', one_hot=True)\n",
    "\n",
    "print ('cell finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, validation, test: 55000, 5000, 10000\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "3\n",
      "784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x13e5e0910>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13e59c910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. There are 55k, 5k, and 10k examples in train, validation, and test.\n",
    "print ('Train, validation, test: %d, %d, %d' % \n",
    "      (len(mnist.train.images), len(mnist.validation.images), len(mnist.test.images)))\n",
    "\n",
    "# show how the labels are represented using one-hot encoding\n",
    "# This is represented as '[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]'\n",
    "print (mnist.train.labels[4])\n",
    "\n",
    "# You can find the index of the label, like this:\n",
    "print (np.argmax(mnist.train.labels[4]))\n",
    "\n",
    "# 3. An image is a 'flattened' array of 28*28 = 784 pixels.\n",
    "print (len(mnist.train.images[4]))\n",
    "\n",
    "# 4. To display an image, first reshape it to 28x28.\n",
    "pylab.imshow(mnist.train.images[4].reshape((28,28)), cmap=pylab.cm.gray_r)   \n",
    "pylab.title('Label: %d' % np.argmax(mnist.train.labels[4])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define various constants to be used in training the model\n",
    "NUM_CLASSES = 10\n",
    "NUM_PIXELS = 28 * 28\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 0.5\n",
    "EPOCHS = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input variables\n",
    "\n",
    "#the input x will be an image\n",
    "x = tf.placeholder(tf.float32, [None,28*28])\n",
    "\n",
    "#the output y will be a one-hot encoded array with a 1 located at the location of the predicted output\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#define the weight matrix to be multiplied by the input, normalize bias to an array of 0's\n",
    "W = tf.Variable(tf.truncated_normal([28*28,10], stddev=0.1))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the matrix multiplication and bias add\n",
    "\n",
    "y = tf.matmul(x,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss using softmax, cross entropy and logits\n",
    "# let's first use a gradient descent optimizer\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell creates the session and initializes all of the variables\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated label = 9 expected label = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x13e9e0c90>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB4kfRE2y57w4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1286f6110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's try the model before we train it to see what happens. Since the weights are random, there is a small chance\n",
    "# that it may work, but if you try different image indices by changing the image_index value below, you will see \n",
    "# that most of the images are miscategorized. Try a few values. The range of allowed values is from 0 to 4999.\n",
    "# Hit shift-enter to run the cell again and recalculate the value\n",
    "\n",
    "# You will re-run this cell again after the model is trained and see the difference\n",
    "\n",
    "image_index = 89\n",
    "exp_label = np.argmax(mnist.test.labels[image_index], 0)\n",
    "x_image = np.reshape(mnist.test.images[image_index], [-1,784])\n",
    "\n",
    "\n",
    "outval = sess.run(y, feed_dict={x:x_image})\n",
    "#this is weird, outval[0] refers to a 1x10 Tensor so the 0 is referring to that 1 part of the dimension\n",
    "label= np.argmax(outval[0],0)\n",
    "\n",
    "print (\"calculated label = {} expected label = {}\".format(label, exp_label))\n",
    "pylab.imshow(mnist.test.images[image_index].reshape((28,28)), cmap=pylab.cm.gray_r)   \n",
    "pylab.title('Label: %d' % np.argmax(mnist.test.labels[image_index])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_step = 0\n",
      "train_step = 100\n",
      "train_step = 200\n",
      "train_step = 300\n",
      "train_step = 400\n",
      "train_step = 500\n",
      "train_step = 600\n",
      "train_step = 700\n",
      "train_step = 800\n",
      "train_step = 900\n",
      "train_step = 1000\n",
      "train_step = 1100\n",
      "train_step = 1200\n",
      "train_step = 1300\n",
      "train_step = 1400\n",
      "train_step = 1500\n",
      "train_step = 1600\n",
      "train_step = 1700\n",
      "train_step = 1800\n",
      "train_step = 1900\n"
     ]
    }
   ],
   "source": [
    "#  \n",
    "for t in range(EPOCHS):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "  if t%100 == 0:\n",
    "    print('train_step = {}'.format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.922109\n",
      "Testing Accuracy:  0.9215\n"
     ]
    }
   ],
   "source": [
    "# Write the code to evaluate the model as we saw in the lecture\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(\"Training Accuracy: \", sess.run(accuracy, feed_dict={x:mnist.train.images, y_:mnist.train.labels}))\n",
    "print(\"Testing Accuracy: \",sess.run(accuracy, feed_dict={x:mnist.test.images, y_:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like logistic regression does a decent job at correctly classifying the test images in the MNIST dataset.  Let's see if we can improve on this model by integrating deeper neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let's reset the graph and begin a new TF session\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define input placeholders \n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a neural network with multiple layers\n",
    "#use the ReLU for the activation function\n",
    "\n",
    "l1w = tf.Variable(tf.truncated_normal([784,500], stddev=0.1))\n",
    "l1b = tf.Variable(tf.constant(0.1,shape=[500]))\n",
    "l1actv = tf.nn.relu(tf.matmul(x,l1w)+ l1b)\n",
    "\n",
    "l2w = tf.Variable(tf.truncated_normal([500,10], stddev=0.1))\n",
    "l2b = tf.Variable(tf.constant(0.1,shape=[10]))\n",
    "\n",
    "y = tf.matmul(l1actv,l2w) + l2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define an error function that reduced the mean error\n",
    "#in this case, let's use the AdamOptimizer rather than the generic Gradient Descent\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call the global variables initializer\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_step = 0\n",
      "train_step = 100\n",
      "train_step = 200\n",
      "train_step = 300\n",
      "train_step = 400\n",
      "train_step = 500\n",
      "train_step = 600\n",
      "train_step = 700\n",
      "train_step = 800\n",
      "train_step = 900\n",
      "train_step = 1000\n",
      "train_step = 1100\n",
      "train_step = 1200\n",
      "train_step = 1300\n",
      "train_step = 1400\n",
      "train_step = 1500\n",
      "train_step = 1600\n",
      "train_step = 1700\n",
      "train_step = 1800\n",
      "train_step = 1900\n"
     ]
    }
   ],
   "source": [
    "# Write the loop to train the new DNN model\n",
    "\n",
    "for t in range(2000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "  if t%100 == 0:\n",
    "    print('train_step = {}'.format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.991636\n",
      "Testing Accuracy:  0.9777\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(\"Training Accuracy: \", sess.run(accuracy, feed_dict={x:mnist.train.images, y_:mnist.train.labels}))\n",
    "print(\"Testing Accuracy: \",sess.run(accuracy, feed_dict={x:mnist.test.images, y_:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like simply adding an additional hidden layer increased the accuracy of our model from 92.15% to 97.78%.  Lets see if we can squeeze even more accuracy out of this by integrating a convolutional neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let's reset the graph and begin a new TF session\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None,784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lets use functions to define the weight and bias variables in this case.\n",
    "#There will be a large amount of variables to define so this will make it easier\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolution and pooling layer parameters will be nearly the same except for the shapes, so we can wrap these in functions as well to provide consistency. We will use a stride of 1 for the conv2d layers with padding equal to SAME. With these settings the output size will be same as the input. The pooling layer will use a pooling of 2 so that the output image is 1/2 the size of the input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define the weights and bias for the first layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reshape the input image from a 1-d array of 784 pixel values\n",
    "#into a 28 x 28 pixel 2-d array\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define our first convolutional and pooling layers\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#repeat the above process for the next layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create the weight variable and bias variable for the first fully connected layer. The weight variable needs to match the size of the final convolutional layer so it needs to have 7 by 7 by 64 inputs and 1024 outputs. The bias variable needs to have a bias value for each of the 1024 output neurons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define our fully connected layer\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the second pooling layer is 64 filters of 7 x 7. The first fully connected layer will consist of 1024 neurons whose inputs are the outputs of the second pooling layer. Since the pooling layer output is 2d, it will need to be reshaped into single dimensional vectors for input to the fully connected layer.\n",
    "\n",
    "After the reshape the fully connected layer takes the weights, biases, and reshaped input and performs a matrix multiply, add, and relu function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use dropout to increase the chances the network generalizes more quickly\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our final convolutional layer and define a matrix multiplication output.  The output of this will be used to predict the digit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define error function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train the model using the AdamOptimizer method\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#metrics for model evaluation\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize a new session\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CNNs typically need more iterations to train with a lower learning rate in comparison to shallower DNNs\n",
    "#these numbers were determined simply by a trial and error process\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        #print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, after training the CNN for 20,000 iterations, lets checkout the accuracy of the convolutional layer to see if we were able improve on our deep neural network model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9927\n",
      "training accuracy 0.999727\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "print(\"training accuracy %g\"%accuracy.eval(feed_dict={x: mnist.train.images, y_: mnist.train.labels, keep_prob: 1.0}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are major improvements from implementing the digit recognition system going from logistic regression, to deep neural networks, and finally to convolutional neural networks. The training and testing accuracies are summarized in the table below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_data = {'Logistic Regression': [0.922, 0.9215], 'DNN': [0.9916, 0.9777], 'CNN': [0.9997,0.9927]}\n",
    "results_data_df = pd.DataFrame(results_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNN</th>\n",
       "      <th>DNN</th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training Accuracy</th>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>0.9220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <td>0.9927</td>\n",
       "      <td>0.9777</td>\n",
       "      <td>0.9215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      CNN     DNN  Logistic Regression\n",
       "Training Accuracy  0.9997  0.9916               0.9220\n",
       "Testing Accuracy   0.9927  0.9777               0.9215"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_data_df.rename(index={0:'Training Accuracy', 1:'Testing Accuracy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing accuracy is the more important metric in this case and it seems that CNN outperforms the other models.  Though all models seem to have a high accuracy, a 1-2% increase in testing accuracy can be massively important depending on the applications of the digit recognition classifier.  For example, if this applications was integrated into a self-driving vehicle that was reading road signs, a system with 92% accuracy would not be acceptable by any standard.  With more sophisticated models, near-perfect accuracy becomes a posssibility.  This of course comes at a great cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
